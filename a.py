
from PIL import Image
def get_image_size(image_path):
    """è·å–å›¾åƒçš„å®½åº¦å’Œé«˜åº¦"""
    with Image.open(image_path) as img:
        return img.size  # è¿”å› (å®½åº¦, é«˜åº¦)
    
# ç¤ºä¾‹ç”¨æ³•
image_path = "lalala/curved_bev_output/__EPszp5486MewfwSMqmSQ,37.742475,-122.404157,.png"  # æ›¿æ¢ä¸ºä½ çš„å›¾åƒè·¯å¾„
width, height = get_image_size(image_path)
print(f"å›¾åƒå®½åº¦: {width}, å›¾åƒé«˜åº¦: {height}")

# import os
# import shutil
# txt_path = '/zssd/dataset/liuyaowei/vigor/SanFrancisco_bev/curved_bev_output/marked/detailed_errors.txt'
# source_folder = '/zssd/dataset/liuyaowei/vigor/SanFrancisco_bev/curved_bev_output/down_image' 
# output_best_dir = '/ssd/liuyaowei/DA-2-main/error_analyze/good'   
# output_worst_dir = '/ssd/liuyaowei/DA-2-main/error_analyze/bad' 
# os.mkdir(output_best_dir)
# os.mkdir(output_worst_dir)
# marked_source_folder = '/zssd/dataset/liuyaowei/vigor/SanFrancisco_bev/curved_bev_output/marked'

# def process_errors_and_copy():
#     data_entries = []
#     if not os.path.exists(txt_path):
#         print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ° txt æ–‡ä»¶ {txt_path}")
#         return

#     print("æ­£åœ¨è¯»å–è¯¦ç»†é”™è¯¯æ–‡ä»¶...")
#     with open(txt_path, 'r', encoding='utf-8') as f:
#         lines = f.readlines()
#     content_lines = lines[1:]

#     for line in content_lines:
#         line = line.strip()
#         if not line:
#             continue
        
#         parts = line.split(',')
#         try:
#             error_val = float(parts[-5])
#             filename = ",".join(parts[:-5]) 
            
#             data_entries.append({
#                 'filename': filename,
#                 'error': error_val
#             })
#         except (ValueError, IndexError):
#             continue
#     sorted_data = sorted(data_entries, key=lambda x: x['error'])
#     best_10 = sorted_data[:10]
#     worst_10 = sorted_data[-10:]
#     print(best_10)
#     print(worst_10)
#     def copy_file_pair(file_list, target_dir, label):
#         if not os.path.exists(target_dir):
#             os.makedirs(target_dir)
        
#         print(f"\n=== å¼€å§‹å¤åˆ¶ {label} (åŒ…å« Original å’Œ Marked) ===")
#         count = 0
#         for item in file_list:
#             fname = item['filename']     # åŸå§‹æ–‡ä»¶åï¼Œå¦‚: xxx,37.1,122.1,.png
#             err = item['error']
            
#             # æ„é€  Marked æ–‡ä»¶å
#             # é€»è¾‘ï¼šå°† ".png" æ›¿æ¢ä¸º "_marked.png"
#             # åŸå§‹: "...,.png" -> æ›¿æ¢å: "...,_marked.png" (ç¬¦åˆæˆªå›¾ä¸­çš„æ ¼å¼)
#             fname_marked = fname.replace('.png', '_marked.png')

#             # æºè·¯å¾„
#             src_origin = os.path.join(source_folder, fname)
#             src_marked = os.path.join(marked_source_folder, fname_marked)

#             # ç›®æ ‡è·¯å¾„ (ä¿æŒåŸå)
#             dst_origin = os.path.join(target_dir, fname)
#             dst_marked = os.path.join(target_dir, fname_marked)

#             # æ‰§è¡Œå¤åˆ¶ - åŸå§‹å›¾
#             try:
#                 shutil.copy2(src_origin, dst_origin)
#                 print(f"[OK] åŸå›¾: {fname} (Err: {err:.4f})")
#             except FileNotFoundError:
#                 print(f"[!!] åŸå›¾æœªæ‰¾åˆ°: {src_origin}")

#             # æ‰§è¡Œå¤åˆ¶ - Marked å›¾
#             try:
#                 shutil.copy2(src_marked, dst_marked)
#                 print(f"     -> Markedå›¾: {fname_marked}")
#             except FileNotFoundError:
#                 print(f"     [!!] Markedå›¾æœªæ‰¾åˆ°: {src_marked}")
            
#             count += 1
#         print(f"å®Œæˆ {label} å¤„ç†ã€‚")
#     copy_file_pair(best_10, output_best_dir, "æœ€å°è¯¯å·® Top 10")
#     copy_file_pair(worst_10, output_worst_dir, "æœ€å¤§è¯¯å·® Top 10")

# if __name__ == "__main__":
#     process_errors_and_copy()



# import cv2
# import numpy as np

# # è¯»å–åŸå›¾å’Œmask
# image = cv2.imread('assets/input_images/_0Ud0q5JrXcYKIpS8GZ0KA,37.776165,-122.403530,.jpg')
# mask = cv2.imread('assets/input_images_masked_car/_0Ud0q5JrXcYKIpS8GZ0KA,37.776165,-122.403530,.jpg', cv2.IMREAD_GRAYSCALE)  # ç°åº¦è¯»å–

# # ç¡®ä¿maskæ˜¯äºŒå€¼æˆ–0-1èŒƒå›´çš„
# if mask.max() > 1:
#     mask = mask / 255.0  # å½’ä¸€åŒ–åˆ°0-1

# # æ‰©å±•maskç»´åº¦ä»¥åŒ¹é…å›¾ç‰‡é€šé“
# mask_3d = cv2.merge([mask, mask, mask])

# # ç›¸ä¹˜
# result = image * mask_3d

# # ä¿å­˜ç»“æœ
# cv2.imwrite('masked_image.jpg', result)

#åˆ¤æ–­ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸‹å¤šå°‘å›¾ç‰‡
# import os

# def count_png_files(folder_path):
#     # 1. æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
#     if not os.path.exists(folder_path):
#         print(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶å¤¹ '{folder_path}' ä¸å­˜åœ¨")
#         return

#     count = 0
#     # 2. éå†æ–‡ä»¶å¤¹
#     # os.listdir åªåˆ—å‡ºå½“å‰æ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶ï¼Œä¸åŒ…å«å­æ–‡ä»¶å¤¹
#     try:
#         files = os.listdir(folder_path)
#         for filename in files:
#             # 3. åˆ¤æ–­åç¼€ (è½¬ä¸ºå°å†™æ¯”è¾ƒï¼Œå¿½ç•¥å¤§å°å†™å·®å¼‚)
#             if filename.lower().endswith(".png"):
#                 count += 1
        
#         print(f"ğŸ“‚ æ–‡ä»¶å¤¹: {folder_path}")
#         print(f"ğŸ“Š PNGå›¾ç‰‡æ•°é‡: {count} å¼ ")
        
#     except Exception as e:
#         print(f"âš ï¸ è¯»å–å‡ºé”™: {e}")

# # --- ä½¿ç”¨æ–¹å¼ ---
# target_folder = "/zssd/dataset/liuyaowei/vigor/Chicago_bev/curved_bev_output/down_image/"  # æ›¿æ¢æˆä½ çš„æ–‡ä»¶å¤¹è·¯å¾„
# count_png_files(target_folder)

# import torch
# import torch.nn as nn
# import torch.nn.functional as F
# from muon import MuonWithAuxAdam  # å‡è®¾è¿™æ˜¯æ‚¨çš„è‡ªå®šä¹‰ä¼˜åŒ–å™¨

# class CompleteModel(nn.Module):
#     def __init__(self, num_classes=10, vocab_size=1000, embed_dim=64):
#         """
#         å®Œæ•´çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼ŒåŒ…å«embeddingã€å·ç§¯ã€çº¿æ€§ç­‰å±‚
        
#         å‚æ•°:
#             num_classes: åˆ†ç±»ç±»åˆ«æ•°
#             vocab_size: è¯æ±‡è¡¨å¤§å°
#             embed_dim: embeddingç»´åº¦
#         """
#         super(CompleteModel, self).__init__()
        
#         # ========== Embedding éƒ¨åˆ† ==========
#         self.embedding = nn.Embedding(vocab_size, embed_dim)
        
#         # ========== å·ç§¯éƒ¨åˆ† ==========
#         # ç¬¬ä¸€ä¸ªå·ç§¯å—
#         self.conv1 = nn.Conv2d(in_channels=embed_dim, out_channels=128, kernel_size=3, padding=1)
#         self.bn1 = nn.BatchNorm2d(128)
        
#         # ç¬¬äºŒä¸ªå·ç§¯å—
#         self.conv2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)
#         self.bn2 = nn.BatchNorm2d(256)
        
#         # ç¬¬ä¸‰ä¸ªå·ç§¯å—
#         self.conv3 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)
#         self.bn3 = nn.BatchNorm2d(512)
        
#         # ç¬¬å››ä¸ªå·ç§¯å—ï¼ˆæ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼‰
#         self.depthwise_conv = nn.Conv2d(512, 512, kernel_size=3, padding=1, groups=512)
#         self.pointwise_conv = nn.Conv2d(512, 256, kernel_size=1)
#         self.bn4 = nn.BatchNorm2d(256)
        
#         # ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶
#         self.spatial_attention = nn.Sequential(
#             nn.Conv2d(256, 1, kernel_size=7, padding=3),
#             nn.Sigmoid()
#         )
        
#         # ========== æ± åŒ–å±‚ ==========
#         self.pool = nn.AdaptiveAvgPool2d((1, 1))
#         self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)
        
#         # ========== å…¨è¿æ¥éƒ¨åˆ† ==========
#         # çº¿æ€§å±‚1
#         self.fc1 = nn.Linear(256, 128)
#         self.dropout1 = nn.Dropout(0.5)
        
#         # çº¿æ€§å±‚2
#         self.fc2 = nn.Linear(128, 64)
#         self.dropout2 = nn.Dropout(0.3)
        
#         # è¾“å‡ºå±‚
#         self.classifier = nn.Linear(64, num_classes)
        
#         # ========== å…¶ä»–å±‚ ==========
#         # æ®‹å·®è¿æ¥çš„1x1å·ç§¯
#         self.residual_conv = nn.Conv2d(embed_dim, 128, kernel_size=1)
        
#         # Layer Normalization
#         self.ln1 = nn.LayerNorm(128)
#         self.ln2 = nn.LayerNorm(256)
        
#         # åˆå§‹åŒ–æƒé‡
#         self._initialize_weights()
    
#     def _initialize_weights(self):
#         """åˆå§‹åŒ–æ¨¡å‹æƒé‡"""
#         for m in self.modules():
#             if isinstance(m, nn.Conv2d):
#                 nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
#                 if m.bias is not None:
#                     nn.init.constant_(m.bias, 0)
#             elif isinstance(m, nn.BatchNorm2d):
#                 nn.init.constant_(m.weight, 1)
#                 nn.init.constant_(m.bias, 0)
#             elif isinstance(m, nn.Linear):
#                 nn.init.normal_(m.weight, 0, 0.01)
#                 nn.init.constant_(m.bias, 0)
#             elif isinstance(m, nn.Embedding):
#                 nn.init.normal_(m.weight, 0, 0.01)
    
#     def forward(self, x, input_shape=(32, 32)):
#         """
#         å‰å‘ä¼ æ’­
        
#         å‚æ•°:
#             x: è¾“å…¥tensor, shape: (batch_size, seq_len) æˆ– (batch_size,)
#             input_shape: è¾“å…¥å›¾åƒå½¢çŠ¶ (H, W)ï¼Œé»˜è®¤32x32
            
#         è¿”å›:
#             output: æ¨¡å‹è¾“å‡º
#         """
#         batch_size = x.size(0)
        
#         # ========== Embedding ==========
#         # å‡è®¾è¾“å…¥æ˜¯åºåˆ—ï¼Œå…ˆembedding
#         if x.dim() == 2:  # (batch_size, seq_len)
#             embedded = self.embedding(x)  # (batch, seq_len, embed_dim)
#             # è½¬æ¢ä¸º2D: å‡è®¾seq_lenå¯¹åº”é«˜åº¦ï¼Œembed_dimå¯¹åº”é€šé“
#             # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
#             h, w = input_shape
#             seq_len = embedded.size(1)
#             embedded = embedded.view(batch_size, -1, h, w)
#         else:  # å¦‚æœå·²ç»æ˜¯2Dè¾“å…¥
#             embedded = self.embedding(x)  # å‡è®¾xæ˜¯ç´¢å¼•
            
#         # ========== å·ç§¯å—1 ==========
#         # æ®‹å·®è¿æ¥
#         residual = self.residual_conv(embedded)
        
#         x = self.conv1(embedded)
#         x = self.bn1(x)
#         x = F.relu(x)
#         x = x + residual  # æ®‹å·®è¿æ¥
#         x = self.max_pool(x)  # ä¸‹é‡‡æ ·
        
#         # ========== å·ç§¯å—2 ==========
#         x = self.conv2(x)
#         x = self.bn2(x)
#         x = F.relu(x)
#         x = self.ln1(x.view(batch_size, 128, -1).transpose(1, 2)).transpose(1, 2).view(x.shape)
#         x = self.max_pool(x)
        
#         # ========== å·ç§¯å—3 ==========
#         x = self.conv3(x)
#         x = self.bn3(x)
#         x = F.relu(x)
#         x = self.max_pool(x)
        
#         # ========== æ·±åº¦å¯åˆ†ç¦»å·ç§¯ ==========
#         x = self.depthwise_conv(x)
#         x = self.pointwise_conv(x)
#         x = self.bn4(x)
#         x = F.relu(x)
        
#         # ========== ç©ºé—´æ³¨æ„åŠ› ==========
#         attention = self.spatial_attention(x)
#         x = x * attention  # åº”ç”¨æ³¨æ„åŠ›
        
#         # ========== å…¨å±€æ± åŒ– ==========
#         x = self.pool(x)  # (batch, 256, 1, 1)
#         x = x.view(batch_size, -1)  # (batch, 256)
        
#         # ========== å…¨è¿æ¥å±‚ ==========
#         x = self.fc1(x)
#         x = F.relu(x)
#         x = self.dropout1(x)
        
#         x = self.fc2(x)
#         x = F.relu(x)
#         x = self.dropout2(x)
        
#         # ========== è¾“å‡ºå±‚ ==========
#         output = self.classifier(x)
        
#         return output


# def create_model_and_optimizer(num_classes=10, vocab_size=1000, embed_dim=64):
#     """
#     åˆ›å»ºæ¨¡å‹å’Œä¼˜åŒ–å™¨
    
#     è¿”å›:
#         model: æ¨¡å‹å®ä¾‹
#         optimizer: ä¼˜åŒ–å™¨å®ä¾‹
#     """
#     # åˆ›å»ºæ¨¡å‹
#     model = CompleteModel(num_classes=num_classes, vocab_size=vocab_size, embed_dim=embed_dim)
    
#     # å®šä¹‰å‚æ•°åˆ†ç»„
#     # 1. äºŒç»´æƒé‡å‚æ•°ï¼ˆä½¿ç”¨Muonï¼‰
#     hidden_weights = [
#         p for name, p in model.named_parameters() 
#         if p.ndim >= 2 and not name.startswith('classifier')
#     ]
    
#     # 2. ä¸€ç»´å‚æ•°ï¼ˆåç½®ã€gainç­‰ï¼Œä¸ä½¿ç”¨Muonï¼‰
#     hidden_gains_biases = [
#         p for name, p in model.named_parameters()
#         if p.ndim < 2 and not name.startswith('classifier')
#     ]
    
#     # 3. åˆ†ç±»å¤´å’Œembeddingå‚æ•°ï¼ˆä¸ä½¿ç”¨Muonï¼‰
#     classifier_params = [p for name, p in model.named_parameters() if name.startswith('classifier')]
#     embedding_params = [p for name, p in model.named_parameters() if 'embedding' in name]
#     nonhidden_params = classifier_params + embedding_params
    
#     # åˆ›å»ºå‚æ•°ç»„
#     param_groups = [
#         # å·ç§¯å’Œå…¨è¿æ¥çš„æƒé‡ä½¿ç”¨Muon
#         {
#             'params': hidden_weights,
#             'use_muon': True,
#             'lr': 0.02,
#             'weight_decay': 0.01,
#             'betas': (0.9, 0.999)  # å¦‚æœéœ€è¦è¦†ç›–é»˜è®¤å€¼
#         },
#         # åç½®ã€BNå‚æ•°ã€åˆ†ç±»å¤´ã€embeddingä¸ä½¿ç”¨Muon
#         {
#             'params': hidden_gains_biases + nonhidden_params,
#             'use_muon': False,
#             'lr': 3e-4,
#             'betas': (0.9, 0.95),
#             'weight_decay': 0.01
#         }
#     ]
    
#     # åˆ›å»ºä¼˜åŒ–å™¨
#     optimizer = MuonWithAuxAdam(param_groups)
    
#     return model, optimizer

# # ä½¿ç”¨ç¤ºä¾‹
# if __name__ == "__main__":
#     model, optimizer = create_model_and_optimizer(
#         num_classes=10,
#         vocab_size=1000,
#         embed_dim=64
#     )
#     # æ‰“å°æ¨¡å‹ç»“æ„
#     print("æ¨¡å‹ç»“æ„:")
#     print(model)
#     print("\næ¨¡å‹å‚æ•°é‡:", sum(p.numel() for p in model.parameters()))
    
#     # æ‰“å°å‚æ•°åˆ†ç»„ä¿¡æ¯
#     print("\nä¼˜åŒ–å™¨å‚æ•°åˆ†ç»„:")
#     for i, group in enumerate(optimizer.param_groups):
#         num_params = sum(p.numel() for p in group['params'])
#         print(f"ç»„ {i}:")
#         print(f"  ä½¿ç”¨Muon: {group.get('use_muon', False)}")
#         print(f"  å­¦ä¹ ç‡: {group.get('lr', 'N/A')}")
#         print(f"  å‚æ•°æ•°é‡: {num_params}")
#         print(f"  å‚æ•°ç¤ºä¾‹: {[p.shape for p in group['params'][:2]] if group['params'] else 'æ— å‚æ•°'}")
    
#     # æµ‹è¯•å‰å‘ä¼ æ’­
#     batch_size = 4
#     seq_len = 100
#     dummy_input = torch.randint(0, 1000, (batch_size, seq_len))
    
#     print("\næµ‹è¯•å‰å‘ä¼ æ’­:")
#     output = model(dummy_input, input_shape=(10, 10))  # å‡è®¾10x10ç‰¹å¾å›¾
#     print(f"è¾“å…¥å½¢çŠ¶: {dummy_input.shape}")
#     print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
#     print(f"è¾“å‡ºç¤ºä¾‹:\n{output}")
    
#     # æµ‹è¯•è®­ç»ƒæ­¥éª¤
#     print("\næµ‹è¯•è®­ç»ƒæ­¥éª¤:")
#     # æ¨¡æ‹ŸæŸå¤±
#     target = torch.randint(0, 10, (batch_size,))
#     criterion = nn.CrossEntropyLoss()
#     loss = criterion(output, target)
    
#     # åå‘ä¼ æ’­
#     optimizer.zero_grad()
#     loss.backward()
#     optimizer.step()
    
#     print(f"æŸå¤±å€¼: {loss.item():.4f}")
#     print("è®­ç»ƒæ­¥éª¤å®Œæˆ!")
